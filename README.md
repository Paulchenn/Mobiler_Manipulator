# Mobile Manipulator: Collision Checking & Path Planning

**Course:** Robot Programming (Roboterprogrammierung)  
**Institution:** Hochschule Karlsruhe (HKA) â€“ Master Robotics and AI in Production (RKIM)  
**Semester:** Winter Semester 2025/2026  
**Lecturer:** Prof. Dr. BjÃ¶rn Hein

## ðŸ“– Project Overview

This repository contains the implementation and evaluation of a planning system for a **planar mobile manipulator**. The system consists of a mobile base (3 Degrees of Freedom: $x, y, \theta$) and a robotic arm with two rotational joints (2 Degrees of Freedom), resulting in a 5-DOF configuration space.

The core objective of this project is the development of a robust **Collision Checker** that handles:

* **Base Collision:** Arbitrary geometric shapes for the mobile base against static obstacles.
* **Arm Collision:** Multi-segment arm collision detection.
* **Self-Collision:** Detection of collisions between the robot's arm and its own base.

Furthermore, the project benchmarks probabilistic sampling-based planning algorithmsâ€”specifically **LazyPRM** and **VisibilityPRM**â€”and simulates a **Pick-and-Place** scenario without the use of inverse kinematics.

## âœ¨ Key Features

### 1. Custom Collision Checker

A geometric collision detection engine (using `shapely` and `numpy`) that supports:

* **Configurable Robot Design:** Define base shape, arm segment lengths, thicknesses, and joint limits.
* **Environment Interaction:** Detects collisions with static obstacles defined in benchmark maps.
* **Self-Collision Logic:** Toggleable checks to prevent the manipulator from clipping through the mobile base.

### 2. Planning Algorithms & Benchmarking

Integration with sampling-based planners to evaluate performance in complex environments:

* **Algorithms:** `LazyPRM` (multi-query, lazy evaluation) vs. `VisibilityPRM` (optimized for narrow passages).
* **Metrics:** Success rate, path length, number of nodes/edges, and computation time.
* **Batch Evaluation:** Automated runner for statistical analysis over multiple runs ($N=10+$).

### 3. Interactive Simulation

* **Jupyter Notebook Interface:** Full control over the simulation via interactive widgets (sliders, dropdowns).
* **Visualization:** Real-time plotting of the robot configuration ($q_1, q_2, x, y, \theta$), obstacles, start/goal states, and resulting paths.
* **Pick-and-Place:** Simulation of attaching an object to the end-effector and transporting it to a target zone.

## ðŸ“‚ Repository Structure

The project is organized as follows:

```text
â”œâ”€â”€ assets/                 # Images, icons, and benchmark map definitions
â”œâ”€â”€ docs/                   # Documentation and LaTeX source for the final report
â”‚   â”œâ”€â”€ LaTeX/              # Thesis/Project report source files
â”‚   â””â”€â”€ ...
â”œâ”€â”€ notebooks/              # Jupyter Notebooks (Main entry point)
â”‚   â””â”€â”€ Mobile_Manipulator_Main.ipynb  # <--- START HERE
â”œâ”€â”€ src/                    # Source code for CollisionChecker and Planners
â”‚   â”œâ”€â”€ planners/           # Implementations of PRM, RRT, and Benchmarking tools
â”‚   â”œâ”€â”€ collision_checker.py# Core collision detection logic
â”‚   â”œâ”€â”€ IPAnimator.py       # Visualization tools
â”‚   â”œâ”€â”€ IPTestSuite.py      # Benchmark scenarios definition
â”‚   â””â”€â”€ ...
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # Project documentation
```

## ðŸš€ Getting Started

Follow these steps to set up the environment and run the simulation.

**Prerequisites**

* **Python 3.8+**
* **Jupyter Notebook** or **JupyterLab**

**Installation**

1. **Clone the Repository**

    ```bash
    git clone [https://github.com/YOUR_USERNAME/Mobiler_Manipulator.git](https://github.com/YOUR_USERNAME/Mobiler_Manipulator.git)
    cd Mobiler_Manipulator
    ```

1. **Create a Virtual Environment (Recommended)**

    ```bash
    python -m venv .venv
    # Windows
    .venv\Scripts\activate
    # Linux/Mac
    source .venv/bin/activate
    ```

1. **Install Dependencies** Install the required libraries (including ```numpy```, ```matplotlib```, ```networkx```, ```shapely```, ```ipympl```):

    ```bash
    pip install -r requirements.txt
    ```

## ðŸ’» Usage

The entire project is controlled via the main Jupyter Notebook.

1. **Launch the Environment**

    Start Jupyter in the repository root:

    ```bash
    jupyter notebook
    ```

    Or however you youse Jupyter-Notebooks.

1. **Open the Main Controller**

    Navigate to the ```notebooks/``` folder and open ```Mobile_Manipulator_Main.ipynb```.

1. **Run the Simulation**

    Execute the cells in order. The notebook is structured into specific phases:

    * **Initialization:** Loads the planner factory and benchmark scenarios (defined in ```IPTestSuite.py```).

    * **Interactive Visualization:** Use the provided UI Widgets to manually move the robot joints and base.

        * Test the Attach Object checkbox to simulate gripping.

        * Observe the "COLLISION" or "FREE" status indicator in real-time.

    * **Planning & Benchmarking:**

        * Run the â€žPlanningâ€œ cells to execute ```LazyPRM``` and ```VisibilityPRM``` on all loaded benchmarks.

        * View the generated paths and success/failure logs.

    * **Evaluation:**

        * Run the â€Batch Evaluatorâ€œ to perform repeated tests (default: 10 runs).

        * Generate boxplots and statistical data comparing the planners.

## âš™ï¸ Configuration

You can customize the robot's physics, the test environments, and collision rules by editing the file ```src/IPTestSuite.py```.

* **Self-Collision Check:** Toggle ```SELF_CHECK = True/False``` to enable or disable collision detection between the robot arm and its own base.

* **Robot Geometry:**

    * Modify ```ROBOT_BASE_SHAPE``` to change the polygon defining the mobile base.

    * Adjust ```ROBOT_ARM_CONFIG``` to change arm segment lengths, thicknesses, or joint limits.

* **Benchmark Scenarios:** You can add or modify obstacles in the ```benchList```. Each benchmark defines specific ```obstacles``` (Polygons/Points) and Start/Goal configurations.

## ðŸ“Š Documentation

For a deep dive into the theoretical background, the extension to prismatic joints, and path optimization strategies, please refer to the project report located in the ```docs/``` directory.

The LaTeX documentation covers:

1. **System Modeling:** Kinematic chains and configuration space.

1. **Algorithm Analysis:** Comparison of Lazy vs. Visibility strategies.

1. **Future Work:** Theoretical expansion to linear axes and trajectory smoothing.

## ðŸ‘¥ Authors & Acknowledgments

Development: Paul Glaser, Tim Schaefer, Felix Wietschel (Students of the Master's program Robotics and AI in Production (HKA)).

Supervision: Prof. Dr. BjÃ¶rn Hein.

Developed for the â€Roboterprogrammierungâ€œ module, Winter Semester 2025/2026.
